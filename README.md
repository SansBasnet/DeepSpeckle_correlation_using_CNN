# Speckle correlation using Deep Learning algorithms on Newtonian fluids

Newtonian fluids such as water with predictable viscosity could be used to perform Dynamic Light Scattering. DLS is used to determine particle size and profiling of polymers in suspension that follow Brownian motion. This relation between the speed of the particles and size is related by the Stokes-Einstein equation.

<img src="https://render.githubusercontent.com/render/math?math=D = {(k_B T)}/{(6 \pi \eta RH)}">

T = translational diffusion coefficient, speed of particle [m/s], T = temperature, Î· = viscosity, R_H = hydrodynamic radius

In DLS, a source of monochromatic light, usually a Laser beam, is projected onto a fluid sample at a fixed distance. The laser beam striking the fluid produces a speckle pattern on fast photon counter at the far end. Time-dependent fluctuations in the scattered light measurement allows us to classify the profile of the impurity within the sample. Rather than this conventional approach we use double-pulse laser, with detector shutter open throughtout the experiment. This allows to caputre specle movement to counter the lack of detectors ability to capture a movement in microsecond order. Since the fluctuations are directly related to the diffusion rate of the particles in the sample, we charted a catalogue of impurities including not limited to the Lake Michigan water, sulphate-rich water, pure water and so on.

Previous experiments sought traditional data analysis approach where individual speckle patterns were evaluated per size distribution. Such methods of one-to-one mapping are computationally intensive and not generalised to seek larger relationships amongst different speckle patterns. In addition, sample perturbations could produce significantly different results. Our approach consits of a novel experimental setup that is data rich as well as economical. Our study shows that our set up of hardware and software is scabale for application outside of laboratory settings. 

A Convolutional Neural Network is a Deep Learning neural network designed for processing structured data arrays such as image. The usage of convolutional layers in a CNN mirrors the structure of the human visual cortex, where a series of layers process an incoming image and identify progressively more complex features. An image is a 2-dimensional array of pixels that can be classified based on its features. Our speckle data is an image data, each row is time-stamped and individual columns a different sample type. The data is randomly split into 70% training and 30% testing sets and later on cross-validated. We apply a CNN model because they very exceptional at picking up on patterns in the input image, such as lines, edges, and gradients. The gradient is the key one as speckles are low resolution images evolving over time. Each particle has its characteristic speckle profile that our deep learning model is able to pick up and quicker and at a higher rate of accuracy.

Using a CNN model, we can identify the substance presence in the Newtonian fluid off categorical data for classification. This method is scalable and impactful in impurity testing as well as in characterising proteins, polymers, parasitic presence, as well as antibody-antigen complex identification in diulated blood samples. Drug industry and marine habitat could use such algorithms to enhance quality control. My thesis is projected to use at least 12 samples of fluids with different species. To best of our knowledge, our testing is of higher quality than other studies given our data incorporates diversity of samples, sensitivity tests and accuracy measurements.
